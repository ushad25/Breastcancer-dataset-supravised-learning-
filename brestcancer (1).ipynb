{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6efd0c-b130-47b0-b13d-fdbd416b8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                   #Formative Assessment: Supervised Learning\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cca4290-dcaa-4c80-a1a2-a030fe59d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the dataset:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Tail of the dataset:\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
      "564                0.2216          0.2060                  0.07115       0  \n",
      "565                0.1628          0.2572                  0.06637       0  \n",
      "566                0.1418          0.2218                  0.07820       0  \n",
      "567                0.2650          0.4087                  0.12400       0  \n",
      "568                0.0000          0.2871                  0.07039       1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "                                              #Loading and Preprocessing\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Display the head and tail of the dataset\n",
    "head = df.head()\n",
    "tail = df.tail()\n",
    "\n",
    "print(\"Head of the dataset:\")\n",
    "print(head)\n",
    "\n",
    "print(\"\\nTail of the dataset:\")\n",
    "print(tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78204143-8ef8-409c-b9b6-ebc186f0b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a2924e-fbc1-4f76-87d4-f9e8f9b6cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c586e-1594-4551-9e1c-451fdec8ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling Missing Values:\n",
    "\n",
    "Step i take : Checking for missing values.\n",
    "Reason: Missing values can negatively impact the performance of machine learning models.\n",
    "However, the breast cancer dataset from sklearn does not contain any missing values,\n",
    "so no further action is needed for this step.\n",
    "    \n",
    "Feature Scaling:\n",
    "\n",
    "Step i take: Standardizing the features using StandardScaler.\n",
    "Reason: Many machine learning algorithms assume that the data is centered around zero and has unit variance.\n",
    "If features are on different scales, algorithms like SVM and k-NN may perform poorly because they rely on distance metrics\n",
    "that are sensitive to the scale of the features. Standardizing the features ensures that each feature contributes equally to\n",
    "the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb77297-b153-4677-9f28-c1199d1e8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = df.drop(columns='target')\n",
    "scaled_features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff8f6cf-d30f-4476-bfef-7d0fb6511dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "scaled_df['target'] = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cb80ef-76b3-49a3-ba69-87cd27d885fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
      "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
      "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
      "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
      "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0          3.283515        2.652874             2.532475       2.217515   \n",
      "1         -0.487072       -0.023846             0.548144       0.001392   \n",
      "2          1.052926        1.363478             2.037231       0.939685   \n",
      "3          3.402909        1.915897             1.451707       2.867383   \n",
      "4          0.539340        1.371011             1.428493      -0.009560   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                2.255747  ...      -1.359293         2.303601    2.001237   \n",
      "1               -0.868652  ...      -0.369203         1.535126    1.890489   \n",
      "2               -0.398008  ...      -0.023974         1.347475    1.456285   \n",
      "3                4.910919  ...       0.133984        -0.249939   -0.550021   \n",
      "4               -0.562450  ...      -1.466770         1.338539    1.220724   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0          1.307686           2.616665         2.109526              2.296076   \n",
      "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
      "2          0.527407           1.082932         0.854974              1.955000   \n",
      "3          3.394275           3.893397         1.989588              2.175786   \n",
      "4          0.220556          -0.313395         0.613179              0.729259   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0        2.750622                 1.937015       0  \n",
      "1       -0.243890                 0.281190       0  \n",
      "2        1.152255                 0.201391       0  \n",
      "3        6.046041                 4.935010       0  \n",
      "4       -0.868353                -0.397100       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141da426-6608-4fbe-864d-5b696fc414cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "                 # Classification Algorithm Implementation\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = scaled_df.drop(columns='target')\n",
    "y = scaled_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c223ee-837b-4f31-9207-8a3a5c11721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f'Logistic Regression Accuracy: {accuracy_log_reg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c278b7-233d-4025-84b6-fa393191ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression is a linear model used for binary classification problems. \n",
    "It predicts the probability of the target variable belonging to a particular class. \n",
    "The model uses the logistic function to map predicted values to probabilities between 0 and 1.\n",
    "Logistic Regression is suitable for the breast cancer dataset as it is a binary classification problem (malignant or benign).\n",
    "It is simple, interpretable, and performs well when the relationship between the features and the target is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce18b675-c6cd-4b12-bd0b-70c40d4f5f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "                           # Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f'Decision Tree Accuracy: {accuracy_tree}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c76a4b-d43b-47d5-8388-3045678a07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision Trees are non-linear models that split the data into subsets based on the value of the features. \n",
    "Each node represents a decision based on a feature, and each branch represents the outcome of that decision.\n",
    "Decision Trees are suitable for the breast cancer dataset as they can capture complex relationships between the features \n",
    "and the target. They are also easy to interpret and can handle both numerical and categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf84a39-c766-4ea7-84f1-9d02a309e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "                        #Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
    "print(f'Random Forest Accuracy: {accuracy_forest}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a4fbc-be23-488b-8dd0-0d72bca928d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest is an ensemble method that combines multiple decision trees to improve the model's performance. \n",
    "It reduces overfitting by averaging the results of several trees.\n",
    "Random Forest is suitable for the breast cancer dataset because it improves the accuracy and robustness of the model by \n",
    "combining multiple decision trees, thus capturing more complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85c0e01-397e-495e-aca3-45665a915410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "                              #kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f'k-NN Accuracy: {accuracy_knn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff2d93-aedb-45b3-a949-4506229a8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM is a powerful classification method that finds the hyperplane that best separates the data into different classes. \n",
    "It works well for both linear and non-linear data by using kernel functions.\n",
    "SVM is suitable for the breast cancer dataset because it can handle high-dimensional spaces and complex decision \n",
    "boundaries, making it effective for datasets with many features like this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91a216ad-68bc-49c8-8631-bea465d88ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "                      #Support Vector Machine (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'SVM Accuracy: {accuracy_svm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedf263-78d4-4b48-bbc9-f1f3636ab60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-NN is a simple, instance-based learning algorithm that classifies a sample based on the majority class of its k-nearest neighbors. \n",
    "It uses distance metrics (e.g., Euclidean) to find the nearest neighbors.\n",
    "k-NN is suitable for the breast cancer dataset because it is a simple and intuitive method that can capture local \n",
    "structures in the data. However, it may not perform well on high-dimensional data without proper feature scaling \n",
    "(which we have already done)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b4955-721f-48ae-8e9f-6f7f4c58199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression: Achieved the highest accuracy of 0.9736842105263158.\n",
    "Random Forest: The second-best performer with an accuracy of 0.9649122807017544.\n",
    "SVM: Close behind with an accuracy of 0.956140350877193.\n",
    "Decision Tree: Achieved an accuracy of 0.9473684210526315.\n",
    "k-NN: Also achieved an accuracy of 0.9473684210526315.\n",
    "Best and Worst Performing Algorithms:-\n",
    "Best Performing Algorithm: Logistic Regression with an accuracy of 0.9736842105263158.\n",
    "Worst Performing Algorithms: Decision Tree and k-NN, both with an accuracy of 0.9473684210526315."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
